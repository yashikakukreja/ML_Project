{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGn4ICrfqXZ"
      },
      "source": [
        "# 1 Author\n",
        "\n",
        "**Student Name**:  Yashika\n",
        "\n",
        "**Student ID**:  220802299\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38VQkcdKd6k"
      },
      "source": [
        "# 2 Problem formulation\n",
        "\n",
        "Here, Using the MLEnd London Sounds dataset, we want to train a machine learning model that takes as an input an audio segment and predicts whether the audio segment has been recorded indoors or outdoors. We will then be evaluating the accuracy of the model on the training and test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BwrtEdLDit"
      },
      "source": [
        "# 3 Machine Learning pipeline\n",
        "\n",
        "Following steps will be carried out:\n",
        "\n",
        "1. First of all, we will extract a sample(of length 1000) of audio files into a location that can be accessed by the program.\n",
        "2. Next, we will load the csv file containing the information of the Sounds dataset(attributes and features) into a pandas dataframe.\n",
        "3. Now we need to identify what features are relevant to classify an audio file as indoor or outdoor. Feature selection is a very important step as the prediction depends on this. If the features are not selected carefully, there is a chance for the model to underfit/overfit. The features selected for this problem statement are:\n",
        "  1. Flatness\n",
        "  2. Signal to noise ratio\n",
        "  3. Energy\n",
        "  4. Chroma\n",
        "4. Next, we will define a function to calculate the values of these features.\n",
        "5. Once the functions are defined, we will iterate over the set of audio files to execute the function to get the values of these features for each audio.\n",
        "After this step, we will have 2 arrays X and Y where X will contain the features of the audio files in the form of some values and Y will contain the actual label of the audio file (0 or 1) i.e. whether the audio has been recorded indoor or outdoor. Here 1 is for indoor and 0 is for outdoor.\n",
        "6. Once we have the datasets, we need to select the model that we need to train. Different types of models can be accurate for different types of datasets. we will analyse the accuracy of the training and test data using different models and will choose the final model according to that.\n",
        "7. Now, we will split our dataset into 2 parts i.e. train and test. We will be using 70% of the datset for training and the remaining 30% for testing.\n",
        "8. Now when we have our datasets ready, we will train the selected model by passing into it the training datset.\n",
        "9. Once this has been done, we will predict the training and validation labels using the trained model and calculate the accuracy for each.\n",
        "10. We can check the change in accuracy by running a number of iterations for steps 7-9.\n",
        "11. Next, we can normalise our dataset and try steps 7-10 again to see if the accuracy improves.\n",
        "12. Finally, we will analyse the accuracy of different models and select the final model based on the results and some facts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1nDXnzYLLH6"
      },
      "source": [
        "# 4 Transformation stage\n",
        "\n",
        "\n",
        "Since our data was in the form of audio files, we could not use it directly to make any predictions. Hence we have to perform transformation on our datset to get relevant features out of it. The input to this step is the set of audio files and the output is a 2D array that contains 4 features for each audio. Each row in X will correspond to an audio file and each column will be a feature as described above. The resulting dataset after transformation will be of the form:\n",
        "\n",
        "X(features): (1000,4)\n",
        "\n",
        "Y(labels): (1000,)\n",
        "\n",
        "The reason for selecting each of the features is:\n",
        "\n",
        "1. Flatness - It provides a way to identify that a sound is a tone or more like noise. This can be helpful in identifying the label as there might be more noise in an audio recorded outdoors as compared to the one recorded indoors.\n",
        "\n",
        "2. Signal to noise ratio - It can be a useful measure to classify an audio as indoor or outdoor as it tells about the performance of an audio signal in terms of noise and signal quality. It compares the strength of the audio signal to the level of noise in the audio. Again, the outdoor recorded audios are more prone to noise as compared to the indoors.\n",
        "\n",
        "3. Energy - The energy of a signal tells about the total magntiude of the signal. For audio signals, it basically tells how loud the signal is. As compared to indoors, the outdoor recorded signals should have energy component on the higher side. Thus, it can be useful in classifying the mentioned label.\n",
        "\n",
        "4. Chroma - This feature relates to the pitch of the sound. It can be useful in identifying the label as the pitch of an outdoor recorded sound might be greater in most cases when compared to indoors recorded sounds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5_kI95LuZ2"
      },
      "source": [
        "# 5 Modelling\n",
        "\n",
        "Here, we will train multiple models i.e. SVM, KNN, Random Forest Classifier and Logistic Regression model. We will analyse the accuracy of our training and test data with each of these models and will choose the appropriate model at the end based on certain results and facts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPTSuaB9L2jU"
      },
      "source": [
        "# 6 Methodology\n",
        "\n",
        "\n",
        "We will divide the X(features) and Y(actual labels) array into 2 parts i.e. train and test. 70% of the data will be used to train the model and the rest 30% will be used to test the model. We will then measure the training and validation accuracy by running a number of iterations. We need to be careful that model should not overfit/underfit in any scenario. We will assess the accuracy of the model mainly by 2 factors:\n",
        "  1. Accuracy on train and test data(both before and after normalisation)\n",
        "  2. Whether the model is underfitting/overfitting\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQPxztuL9AW"
      },
      "source": [
        "# 7 Dataset\n",
        "\n",
        "We have the following data to train and test our model as per the problem statement:\n",
        "  1. Sample of 1000 audio files\n",
        "  2. A CSV file that contains the following information about each audio:\n",
        "    * **file_id** - name of the audio file, which will be same as the audio name that we have already extracted.\n",
        "    * **area** - The area where the audio file has been recorded. It can contain the following 6 values:\n",
        "      * british\n",
        "      * kensington\n",
        "      * campus\n",
        "      * westend\n",
        "      * Euston\n",
        "      * southbank\n",
        "    * **spot** - The particular spot in that area where the audio has been recorded. Each of the 6 areas can have 6 different values for the spot. These are described as below:\n",
        "\n",
        "          british - street, forecourt, greatcourt, room12, square, room13\n",
        "\n",
        "          campus - canal, curve, ground, library, reception, square\n",
        "\n",
        "          Euston - forecourt, gardens, library, piazza, ritblat, upper\n",
        "\n",
        "          kensington -  albert, cromwell, dinosaur, hintze, marine, pond\n",
        "\n",
        "          southbank - book, bridge, food, royal, skate, waterloo\n",
        "\n",
        "          westend - charing, leicester, market, national, piazza, trafalgar\n",
        "    * **in_out** - This column can contain 2 different values:\n",
        "      * indoor - If the audio file has been recorded indoors\n",
        "      * outdoor - If the audio file has been recorded outdoors\n",
        "    * **Participant** - The task of recording audios was carried out by various participants. This column contains the participant id of the person who has recorded the audio.\n",
        "\n",
        "\n",
        "We cannot use the audio files directly to train our model. Thus we need to extract some features out of it that will be further passed as input to the model. Functions have been defined to extract the features and the code for feature extraction is shown below. \n",
        "\n",
        "Also, we need to load our csv file in a pandas dataframe, so that we can perform operations on it.\n",
        "\n",
        "The output of the Transformation step will be 2 2-Dimensional arrays:\n",
        "\n",
        "X(Array of attributes) - Shape of this will be (1000,4) where each row will represent an audio file and each column will correspond to a feature.\n",
        "\n",
        "Y(array of labels) - Shape of this will be (1000,) and this array will contain the actual labels of the corresponding entries in X.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os, sys, re, pickle, glob\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "import scipy.io.wavfile as wavfile\n",
        "import os.path\n",
        "import scipy.stats as stats\n",
        "import scipy\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMHN_4FNAsx1",
        "outputId": "36971e67-0032-41ba-d4a2-64013ac78c72"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_path = '/content/drive/MyDrive/Data/MLEndLS/sample/*.wav'\n",
        "files = glob.glob(sample_path) # Storing all the files matching the pattern oin a variable\n",
        "print(\"Total number of audio files is: \", len(files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP8SWFzqCT-f",
        "outputId": "3a49790c-7dd8-48be-c269-789ff95f5091"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of audio files is:  1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MLENDLS_df = pd.read_csv('./MLEndLS.csv').set_index('file_id') # Loading csv to dataframe\n",
        "MLENDLS_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "HRNIO0mdBij9",
        "outputId": "1ca98eb9-c59d-4713-d07a-51bfd4488f53"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                area       spot   in_out Participant\n",
              "file_id                                             \n",
              "0001.wav     british     street  outdoor        S151\n",
              "0002.wav  kensington   dinosaur   indoor        S127\n",
              "0003.wav      campus     square  outdoor         S18\n",
              "0004.wav  kensington     hintze   indoor        S179\n",
              "0005.wav      campus     square  outdoor        S176\n",
              "...              ...        ...      ...         ...\n",
              "2496.wav     westend  trafalgar  outdoor        S151\n",
              "2497.wav      campus     square  outdoor          S6\n",
              "2498.wav     westend   national   indoor         S96\n",
              "2499.wav     british     room12   indoor         S73\n",
              "2500.wav     british     room12   indoor         S58\n",
              "\n",
              "[2500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-629bfd46-76c6-4488-896f-2743ec5b40b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area</th>\n",
              "      <th>spot</th>\n",
              "      <th>in_out</th>\n",
              "      <th>Participant</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>file_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0001.wav</th>\n",
              "      <td>british</td>\n",
              "      <td>street</td>\n",
              "      <td>outdoor</td>\n",
              "      <td>S151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0002.wav</th>\n",
              "      <td>kensington</td>\n",
              "      <td>dinosaur</td>\n",
              "      <td>indoor</td>\n",
              "      <td>S127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0003.wav</th>\n",
              "      <td>campus</td>\n",
              "      <td>square</td>\n",
              "      <td>outdoor</td>\n",
              "      <td>S18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0004.wav</th>\n",
              "      <td>kensington</td>\n",
              "      <td>hintze</td>\n",
              "      <td>indoor</td>\n",
              "      <td>S179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0005.wav</th>\n",
              "      <td>campus</td>\n",
              "      <td>square</td>\n",
              "      <td>outdoor</td>\n",
              "      <td>S176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496.wav</th>\n",
              "      <td>westend</td>\n",
              "      <td>trafalgar</td>\n",
              "      <td>outdoor</td>\n",
              "      <td>S151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497.wav</th>\n",
              "      <td>campus</td>\n",
              "      <td>square</td>\n",
              "      <td>outdoor</td>\n",
              "      <td>S6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498.wav</th>\n",
              "      <td>westend</td>\n",
              "      <td>national</td>\n",
              "      <td>indoor</td>\n",
              "      <td>S96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499.wav</th>\n",
              "      <td>british</td>\n",
              "      <td>room12</td>\n",
              "      <td>indoor</td>\n",
              "      <td>S73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500.wav</th>\n",
              "      <td>british</td>\n",
              "      <td>room12</td>\n",
              "      <td>indoor</td>\n",
              "      <td>S58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2500 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-629bfd46-76c6-4488-896f-2743ec5b40b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-629bfd46-76c6-4488-896f-2743ec5b40b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-629bfd46-76c6-4488-896f-2743ec5b40b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def signaltonoise(a, axis=0, ddof=0):\n",
        "    a = np.asanyarray(a)\n",
        "    m = a.mean(axis)\n",
        "    sd = a.std(axis=axis, ddof=ddof)\n",
        "    return np.where(sd == 0, 0, m/sd)\n",
        "def snr(file):\n",
        "  data = wavfile.read(file)[1]\n",
        "  singleChannel = data\n",
        "  try:\n",
        "    singleChannel = np.sum(data, axis=1)\n",
        "  except:\n",
        "    pass\n",
        "    \n",
        "  norm = singleChannel / (max(np.amax(singleChannel), -1 * np.amin(singleChannel)))\n",
        "  return signaltonoise(norm)"
      ],
      "metadata": {
        "id": "XDjfuflsBuCB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getEnergy(x,fs,winLen=0.02):\n",
        "  p = winLen*fs\n",
        "  frame_length = int(2**int(p-1).bit_length())\n",
        "  hop_length = frame_length//2\n",
        "  rmse = librosa.feature.rms(x, frame_length=frame_length, hop_length=hop_length, center=True)\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "40AvQct8B1zS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' This function will be used to extract the features from the audio files'''\n",
        "\n",
        "def get_features_labels(files,labels_file, scale_audio=False, onlySingleDigit=False):\n",
        "  X,y =[],[]\n",
        "  for file in tqdm(files):\n",
        "    try:\n",
        "      fileID = file.split('/')[-1]\n",
        "      file_name = file.split('/')[-1]\n",
        "      yi = labels_file.loc[fileID]['in_out']=='indoor'\n",
        "\n",
        "      fs = None # if None, fs = 22050\n",
        "      x, fs = librosa.load(file,sr=fs)\n",
        "      energy = np.mean(getEnergy(x,fs,winLen=0.02))\n",
        "      tempo, beat_frames = librosa.beat.beat_track(y=x, sr=fs)\n",
        "      flatness = np.mean(librosa.feature.spectral_flatness(y=x))\n",
        "      chroma = np.mean(librosa.feature.chroma_stft(x))\n",
        "      snratio = snr(file)\n",
        "\n",
        "      xi = [flatness, snratio, energy, chroma]\n",
        "      X.append(xi)\n",
        "      y.append(yi)\n",
        "    except Exception as e:\n",
        "      print(\"Broken file: \", file)\n",
        "\n",
        "  return np.array(X),np.array(y)"
      ],
      "metadata": {
        "id": "ny4KrtOTB6JC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = get_features_labels(files, labels_file=MLENDLS_df, scale_audio=True, onlySingleDigit=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzmN_plrCG2n",
        "outputId": "0b4c484a-741a-4387-a7bf-fcbc29f42fe8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [07:27<00:00,  2.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The shape of X is', X.shape) \n",
        "print('The shape of y is', y.shape)\n",
        "print('The labels vector is', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG-FzJvFCfOS",
        "outputId": "505b2a95-7dad-4f89-aa2c-78ce1fa621bf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of X is (1000, 4)\n",
            "The shape of y is (1000,)\n",
            "The labels vector is [False False False  True False False False  True False  True False False\n",
            "  True False False False  True False  True  True False False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            " False False False False  True  True False False False False  True False\n",
            " False False  True False  True False  True False  True  True  True False\n",
            " False False  True  True False  True False False False  True  True False\n",
            " False False False False  True False  True  True  True False False False\n",
            "  True False  True False  True False  True  True False False  True False\n",
            " False False  True  True  True False False False False False  True False\n",
            " False False  True False False  True  True  True False  True  True  True\n",
            "  True  True  True  True  True  True False False False  True  True False\n",
            "  True  True  True  True False False False False False  True False False\n",
            " False  True  True  True False  True  True False False False  True False\n",
            " False False False False  True  True False  True  True False False False\n",
            " False False False  True False False  True  True False False  True False\n",
            "  True False  True  True False  True False False  True False  True False\n",
            " False  True  True  True  True False False  True False False False False\n",
            " False False False False  True  True  True False False False False False\n",
            "  True False False False False  True False False  True  True  True False\n",
            "  True  True False False False False False  True  True False False  True\n",
            "  True  True False  True False False  True False False  True False False\n",
            " False  True  True False False  True  True  True  True  True False False\n",
            " False  True False False  True  True False  True False False  True  True\n",
            " False False  True False  True False False  True False  True False  True\n",
            " False False False False False False  True False False False False  True\n",
            "  True  True False False  True  True False False False False False  True\n",
            " False False False False  True False False False False  True False  True\n",
            "  True False False False  True False  True False False  True False  True\n",
            " False  True False False False  True  True  True False False False False\n",
            "  True False  True  True False False  True False False  True  True False\n",
            " False False False  True False  True False  True  True False False  True\n",
            "  True  True False  True  True  True  True False False False False  True\n",
            "  True False False False False  True  True  True False False  True False\n",
            " False  True  True False  True False False  True False  True  True False\n",
            " False False False False False False False False False False  True False\n",
            "  True  True False False  True  True False  True  True False  True False\n",
            "  True  True  True False False False False False False  True False  True\n",
            "  True  True False False  True False  True False  True False False  True\n",
            "  True  True  True  True False  True  True  True  True False False False\n",
            " False False False False  True  True  True  True  True False False False\n",
            "  True  True False False  True False False  True False  True False False\n",
            " False False  True  True False False False False  True False False  True\n",
            " False False  True False  True  True False False  True  True False False\n",
            "  True False False False False False False False False  True  True  True\n",
            " False False  True False False  True False False  True  True False False\n",
            "  True  True False  True False False False  True False  True False  True\n",
            " False  True False  True False  True  True False  True  True False False\n",
            " False False False False False  True  True False  True  True  True False\n",
            " False  True  True  True False False False  True False  True False False\n",
            " False  True False  True  True  True  True  True  True  True False  True\n",
            " False False  True  True False False  True False  True  True False False\n",
            "  True False False False  True False False  True  True  True False False\n",
            "  True  True False  True False False False  True False False False False\n",
            " False  True False False  True False  True  True False  True False  True\n",
            " False  True  True False  True False  True  True  True  True  True False\n",
            "  True  True  True False False  True  True False False False False  True\n",
            "  True  True False  True  True  True  True  True False  True  True  True\n",
            "  True False  True  True  True False False  True  True False False False\n",
            "  True  True  True  True False False False False  True  True False False\n",
            " False  True False  True False  True  True  True False  True  True False\n",
            " False False False False  True False  True False False  True False  True\n",
            "  True  True  True False  True False False False  True  True False False\n",
            "  True False False  True False False  True False False  True False False\n",
            "  True  True  True  True  True False False  True  True False False  True\n",
            "  True  True False False  True  True  True False False False  True False\n",
            "  True False False False  True  True  True  True False False False  True\n",
            " False False False  True False False  True False  True  True False False\n",
            " False  True False False False False False  True  True  True  True False\n",
            " False  True False  True  True False  True  True False False  True False\n",
            "  True False False False  True  True False False False False  True False\n",
            "  True False False False  True False False False  True False False  True\n",
            "  True False  True  True  True False  True  True  True  True  True  True\n",
            " False  True False  True False  True  True False  True  True  True False\n",
            "  True  True False  True  True  True False False  True  True False  True\n",
            "  True  True  True  True  True  True False  True  True False False  True\n",
            " False False False  True False  True False  True  True False False False\n",
            "  True False False  True False False  True False False False  True  True\n",
            "  True  True  True False False False False False False False False False\n",
            "  True False False  True  True False False  True False  True False  True\n",
            " False False False  True False  True False  True  True  True  True  True\n",
            "  True False  True False False  True False  True False False False False\n",
            " False  True  True  True  True False  True  True  True  True False False\n",
            "  True False  True  True  True  True False  True  True  True False  True\n",
            " False  True False False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' The number of indoor recordings is ', np.count_nonzero(y))\n",
        "print(' The number of outdoor recordings is ', y.size - np.count_nonzero(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_kopiWRCiLI",
        "outputId": "bf60ef57-131d-4278-a443-a52c209abc43"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The number of indoor recordings is  457\n",
            " The number of outdoor recordings is  543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qf7GN1aeXJI"
      },
      "source": [
        "# 8 Results\n",
        "\n",
        "Now, when we have our arrays of attributes and labels ready, we need to carry out the main task of training the mdoel and analysing the training and validation accuracy to select the right model. We will be doing it here.\n",
        "\n",
        "We will train 4 different models of supervised learning:\n",
        "\n",
        "  **Support Vector Machine** - This model finds a hyperplane in an N-dimensional space(where N is the number of features, 4 in our case) to classify the data points. The objective of this model is to find the best hyperplane where best means the one having maximum margin i.e. the maimum dstance between data points of classes. \n",
        "\n",
        "  **k nearest neighbour** - This is based on the notion that the features of a datapoint can be predicted based on the features of its neighbours.\n",
        "\n",
        "  **Logistic Regression Model** - The binary logistic regression model is used in the cases where there are 2 classes. It is mostly used with categorical classes.\n",
        "\n",
        "  **Random Forest Classifier** - This model is efficient in classifying large datsets. the accuracy of this model is better than a decision tree because it uses a collection of decision trees, and each tree in the ensemble is comprised of a data sample drawn from a training set with replacement."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.3)\n",
        "print(\"The shape of training set(X) is : {}\\nThe shape of validation set(X) is : {}\\nThe shape of training set(Y) is : {}\\nThe shape of validation set(Y) is : {}\".format(X_train.shape, X_val.shape, y_train.shape, y_val.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5uyLNrJCk9J",
        "outputId": "33e3f56f-d5f7-4f34-9d5b-6e7fd3c1b028"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of training set(X) is : (700, 4)\n",
            "The shape of validation set(X) is : (300, 4)\n",
            "The shape of training set(Y) is : (700,)\n",
            "The shape of validation set(Y) is : (300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' The number of indoor recordings in training dataset is ', np.count_nonzero(y_train))\n",
        "print(' The number of outdoor recordings in training dataset is ', y_train.size - np.count_nonzero(y_train))\n",
        "print(' The number of indoor recordings in validation dataset is ', np.count_nonzero(y_val))\n",
        "print(' The number of outdoor recordings in validation dataset is ', y_val.size - np.count_nonzero(y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N93xIkGvk8rw",
        "outputId": "9aab5fbd-b668-4551-8c47-56f80a8111cf"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The number of indoor recordings in training dataset is  319\n",
            " The number of outdoor recordings in training dataset is  381\n",
            " The number of indoor recordings in validation dataset is  138\n",
            " The number of outdoor recordings in validation dataset is  162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model  = svm.SVC(C=1)\n",
        "model.fit(X_train,y_train)\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "train_labels = np.unique(y_train)\n",
        "val_labels = np.unique(y_val)\n",
        "\n",
        "print(\"--------FOR SVM MODEL-------\")\n",
        "print('Training Accuracy', np.mean(yt_p==y_train))\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val))\n",
        "conf_matrix_train = metrics.confusion_matrix(y_train, yt_p, labels=train_labels)\n",
        "conf_matrix_val = metrics.confusion_matrix(y_val, yv_p, labels=val_labels)\n",
        "\n",
        "print('Training confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_train, index=train_labels, columns=train_labels)))\n",
        "print('Validation confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_val, index=val_labels, columns=val_labels)))\n",
        "\n",
        "model  = KNeighborsClassifier()\n",
        "model.fit(X_train,y_train)\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "print(\"\\n\\n--------FOR KNN MODEL-------\")\n",
        "print('Training Accuracy', np.mean(yt_p==y_train))\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val))\n",
        "conf_matrix_train = metrics.confusion_matrix(y_train, yt_p, labels=train_labels)\n",
        "conf_matrix_val = metrics.confusion_matrix(y_val, yv_p, labels=val_labels)\n",
        "\n",
        "print('Training confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_train, index=train_labels, columns=train_labels)))\n",
        "print('Validation confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_val, index=val_labels, columns=val_labels)))\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train,y_train)\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "print(\"\\n\\n--------FOR LOGISTIC REGRESSION MODEL-------\")\n",
        "print('Training Accuracy', np.mean(yt_p==y_train))\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val))\n",
        "conf_matrix_train = metrics.confusion_matrix(y_train, yt_p, labels=train_labels)\n",
        "conf_matrix_val = metrics.confusion_matrix(y_val, yv_p, labels=val_labels)\n",
        "\n",
        "print('Training confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_train, index=train_labels, columns=train_labels)))\n",
        "print('Validation confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_val, index=val_labels, columns=val_labels)))\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train,y_train)\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "print(\"\\n\\n--------FOR RANDOM FOREST CLASSIFIER MODEL-------\")\n",
        "print('Training Accuracy', np.mean(yt_p==y_train))\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val))\n",
        "conf_matrix_train = metrics.confusion_matrix(y_train, yt_p, labels=train_labels)\n",
        "conf_matrix_val = metrics.confusion_matrix(y_val, yv_p, labels=val_labels)\n",
        "\n",
        "print('Training confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_train, index=train_labels, columns=train_labels)))\n",
        "print('Validation confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_val, index=val_labels, columns=val_labels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gI0VD9iCpdD",
        "outputId": "55eeb31f-85d6-4773-cff6-53307c327e54"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------FOR SVM MODEL-------\n",
            "Training Accuracy 0.7042857142857143\n",
            "Validation  Accuracy 0.6833333333333333\n",
            "Training confusion matrix:\n",
            "        False  True\n",
            "False    214   158\n",
            "True      49   279\n",
            "\n",
            "Validation confusion matrix:\n",
            "        False  True\n",
            "False     98    73\n",
            "True      22   107\n",
            "\n",
            "\n",
            "\n",
            "--------FOR KNN MODEL-------\n",
            "Training Accuracy 0.7742857142857142\n",
            "Validation  Accuracy 0.6433333333333333\n",
            "Training confusion matrix:\n",
            "        False  True\n",
            "False    286    86\n",
            "True      72   256\n",
            "\n",
            "Validation confusion matrix:\n",
            "        False  True\n",
            "False    112    59\n",
            "True      48    81\n",
            "\n",
            "\n",
            "\n",
            "--------FOR LOGISTIC REGRESSION MODEL-------\n",
            "Training Accuracy 0.6085714285714285\n",
            "Validation  Accuracy 0.6366666666666667\n",
            "Training confusion matrix:\n",
            "        False  True\n",
            "False    277    95\n",
            "True     179   149\n",
            "\n",
            "Validation confusion matrix:\n",
            "        False  True\n",
            "False    131    40\n",
            "True      69    60\n",
            "\n",
            "\n",
            "\n",
            "--------FOR RANDOM FOREST CLASSIFIER MODEL-------\n",
            "Training Accuracy 1.0\n",
            "Validation  Accuracy 0.67\n",
            "Training confusion matrix:\n",
            "        False  True\n",
            "False    372     0\n",
            "True       0   328\n",
            "\n",
            "Validation confusion matrix:\n",
            "        False  True\n",
            "False    125    46\n",
            "True      53    76\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix here represents the number of times that an actual value was predicted correctly/incorrectly. The diagonal of the confusion matrix has the values of True Positives.\n",
        "\n",
        "For example if we see the confusion matrix of SVM model, in training set, out of 319 times when the audio was actually indoor, it was predicted correct 279 times and out of 381 times when the adio was outdoor, it was predicted correct 214 times. An outdoor recording was predicted as indoor 158 times while the opposite occured 49 times.\n",
        "Similarly, we can see for validation set."
      ],
      "metadata": {
        "id": "FQNDZF_-kENw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalising the dataset and calculating the accuracy again"
      ],
      "metadata": {
        "id": "BWGAeALNJ_hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = X_train.mean(0)\n",
        "sd =  X_train.std(0)\n",
        "\n",
        "X_train = (X_train-mean)/sd\n",
        "X_val  = (X_val-mean)/sd\n",
        "\n",
        "model  = svm.SVC(C=1)\n",
        "model.fit(X_train,y_train)\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "train_labels = np.unique(y_train)\n",
        "val_labels = np.unique(y_val)\n",
        "\n",
        "\n",
        "print(\"--------FOR SVM MODEL-------\")\n",
        "print('Training Accuracy', np.mean(yt_p==y_train))\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val))\n",
        "conf_matrix_train = metrics.confusion_matrix(y_train, yt_p, labels=train_labels)\n",
        "conf_matrix_val = metrics.confusion_matrix(y_val, yv_p, labels=val_labels)\n",
        "\n",
        "print('Training confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_train, index=train_labels, columns=train_labels)))\n",
        "print('Validation confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_val, index=val_labels, columns=val_labels)))\n",
        "\n",
        "model  = KNeighborsClassifier()\n",
        "model.fit(X_train,y_train)\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "print(\"\\n\\n--------FOR KNN MODEL-------\")\n",
        "print('Training Accuracy', np.mean(yt_p==y_train))\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val))\n",
        "conf_matrix_train = metrics.confusion_matrix(y_train, yt_p, labels=train_labels)\n",
        "conf_matrix_val = metrics.confusion_matrix(y_val, yv_p, labels=val_labels)\n",
        "\n",
        "print('Training confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_train, index=train_labels, columns=train_labels)))\n",
        "print('Validation confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_val, index=val_labels, columns=val_labels)))\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train,y_train)\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "print(\"\\n\\n--------FOR LOGISTIC REGRESSION MODEL-------\")\n",
        "print('Training Accuracy', np.mean(yt_p==y_train))\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val))\n",
        "conf_matrix_train = metrics.confusion_matrix(y_train, yt_p, labels=train_labels)\n",
        "conf_matrix_val = metrics.confusion_matrix(y_val, yv_p, labels=val_labels)\n",
        "\n",
        "print('Training confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_train, index=train_labels, columns=train_labels)))\n",
        "print('Validation confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_val, index=val_labels, columns=val_labels)))\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train,y_train)\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "print(\"\\n\\n--------FOR RANDOM FOREST CLASSIFIER MODEL-------\")\n",
        "print('Training Accuracy', np.mean(yt_p==y_train))\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val))\n",
        "conf_matrix_train = metrics.confusion_matrix(y_train, yt_p, labels=train_labels)\n",
        "conf_matrix_val = metrics.confusion_matrix(y_val, yv_p, labels=val_labels)\n",
        "\n",
        "print('Training confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_train, index=train_labels, columns=train_labels)))\n",
        "print('Validation confusion matrix:\\n {}\\n'.format(pd.DataFrame(conf_matrix_val, index=val_labels, columns=val_labels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ING9mFaxCuLJ",
        "outputId": "b2d56920-e029-4952-f0bf-45e7a0d28e76"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------FOR SVM MODEL-------\n",
            "Training Accuracy 0.7171428571428572\n",
            "Validation  Accuracy 0.74\n",
            "Training confusion matrix:\n",
            "        False  True\n",
            "False    250   132\n",
            "True      66   252\n",
            "\n",
            "Validation confusion matrix:\n",
            "        False  True\n",
            "False    111    50\n",
            "True      28   111\n",
            "\n",
            "\n",
            "\n",
            "--------FOR KNN MODEL-------\n",
            "Training Accuracy 0.7728571428571429\n",
            "Validation  Accuracy 0.68\n",
            "Training confusion matrix:\n",
            "        False  True\n",
            "False    304    78\n",
            "True      81   237\n",
            "\n",
            "Validation confusion matrix:\n",
            "        False  True\n",
            "False    117    44\n",
            "True      52    87\n",
            "\n",
            "\n",
            "\n",
            "--------FOR LOGISTIC REGRESSION MODEL-------\n",
            "Training Accuracy 0.6442857142857142\n",
            "Validation  Accuracy 0.6833333333333333\n",
            "Training confusion matrix:\n",
            "        False  True\n",
            "False    267   115\n",
            "True     134   184\n",
            "\n",
            "Validation confusion matrix:\n",
            "        False  True\n",
            "False    120    41\n",
            "True      54    85\n",
            "\n",
            "\n",
            "\n",
            "--------FOR RANDOM FOREST CLASSIFIER MODEL-------\n",
            "Training Accuracy 1.0\n",
            "Validation  Accuracy 0.69\n",
            "Training confusion matrix:\n",
            "        False  True\n",
            "False    382     0\n",
            "True       0   318\n",
            "\n",
            "Validation confusion matrix:\n",
            "        False  True\n",
            "False    113    48\n",
            "True      45    94\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the results that both SVM and KNN model are giving a good accuracy both before and after normalisation. The Random Forest classifier is always gicing a Tarining accuracy of 100%, so this model is overfitting. From SVM and KNN, SVM is giving a slightly better accuracy than the latter and also, we can observe that KNN is overfitting. So we will choose SVM."
      ],
      "metadata": {
        "id": "XvRH0zLiKM6u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSrJCR_cekPO"
      },
      "source": [
        "# 9 Conclusions\n",
        "\n",
        "Here, we will select the SVM model, because the Support Vector Machine model is a good choice when we have 2 classes. We can also see from the test results that the SVM is giving a good accuracy and minimum difference between the training and validation accuracy as compared to the other models i.e. overfitting is minimum. Here we have a binary label i.e. we need to classify the audio samples as 0 or 1(outdoor or indoor). An SVM classifies data by finding the best hyperplane that separates all data points of one class from those of the other class.\n",
        "\n",
        "Improvements:\n",
        "\n",
        "Between SVM and Logistic Regression models, there was minor difference of accuracy. There is a possibility of change in accuracy if we increase the sample size. Thus we can try to train the models by passing larger sample sizes and then compare the  respective accuracy of both models.\n",
        "Although, we have tried to take the most relevant features of the audio files,  we can try taking other features based on which the accuracy of the model can be improved."
      ]
    }
  ]
}